import streamlit as st
import sys
import os
import json
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ í™•ë³´
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../")))

from src.services import agent
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_core.output_parsers import StrOutputParser

from src.core.config import settings

# ==============================================================================
# 0. í—¬í¼ í•¨ìˆ˜: í›„ì† ì§ˆë¬¸ ìƒì„±ê¸°
# ==============================================================================

def generate_followup_questions(last_query, last_answer):
    """
    LLMì„ ì´ìš©í•´ ì‚¬ìš©ìê°€ ë‹¤ìŒì— ë¬¼ì–´ë³¼ ë§Œí•œ ì§ˆë¬¸ 3ê°€ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´)
        if settings.LLM_PROVIDER == "openai":
            llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.OPENAI_API_KEY, temperature=0.7)
        else:
            llm = ChatOllama(model=settings.OLLAMA_MODEL, temperature=0.7, base_url=settings.OLLAMA_BASE_URL)

        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful assistant suggesting follow-up questions for a cyber security analyst."),
            ("human", f"""
            Based on the user's previous question and the agent's answer, suggest 3 short, relevant follow-up questions in Korean.
            Return ONLY the questions, separated by pipes (|). Do not add numbering or quotes.
            
            [User Question] {last_query}
            [Agent Answer] {last_answer}
            
            Example format: ì´ ê³µê²©ì— ì‚¬ìš©ëœ ë‹¤ë¥¸ IPëŠ” ë­ì•¼?|ê´€ë ¨ëœ í•´í‚¹ ê·¸ë£¹ì€ ëˆ„êµ¬ì•¼?|ëŒ€ì‘ ë°©ì•ˆì€ ì–´ë–»ê²Œ ë¼?
            """)
        ])
        
        chain = prompt | llm | StrOutputParser()
        result = chain.invoke({})
        return [q.strip() for q in result.split('|') if q.strip()][:3]
    except:
        return [] # ì—ëŸ¬ ë‚˜ë©´ ì¶”ì²œ ì§ˆë¬¸ ì•ˆ ë„ì›€

# ==============================================================================
# 1. í˜ì´ì§€ ì„¤ì •
# ==============================================================================
st.set_page_config(page_title="Smart Agent", page_icon="ğŸ•µï¸â€â™‚ï¸", layout="wide")

st.title("ğŸ•µï¸â€â™‚ï¸ Smart Agent (Chatbot)")
st.markdown("""
**Neo4j Knowledge Graph**ì™€ ì—°ë™ëœ AI ë³´ì•ˆ ë¶„ì„ê°€ì…ë‹ˆë‹¤.  
**Incident(ì‚¬ê±´), Malware, Threat Group, IoC** ì •ë³´ë¥¼ ë¬¸ë§¥(Context) ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
""")

# ==============================================================================
# 2. Session State ì´ˆê¸°í™”
# ==============================================================================
if "messages" not in st.session_state:
    st.session_state.messages = []

if "langchain_history" not in st.session_state:
    st.session_state.langchain_history = []

# ì…ë ¥ íŠ¸ë¦¬ê±° ê´€ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜
if "trigger_query" not in st.session_state:
    st.session_state.trigger_query = None

# ë§ˆì§€ë§‰ ë‹µë³€ì— ëŒ€í•œ í›„ì† ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ì €ì¥
if "followup_suggestions" not in st.session_state:
    st.session_state.followup_suggestions = []

# ==============================================================================
# 3. ì‚¬ì´ë“œë°”: ìƒ˜í”Œ ì§ˆë¬¸ (ì—…ë°ì´íŠ¸ë¨)
# ==============================================================================
with st.sidebar:
    st.header("ğŸ“ Sample Questions")
    st.caption("í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ ì§ˆë¬¸í•©ë‹ˆë‹¤.")
    
    # [ë³€ê²½] ìŠ¤í‚¤ë§ˆ(Incident -> Step -> Entity)ì— ë§ì¶˜ ì§ˆë¬¸ë“¤ë¡œ êµì²´
    sample_questions = [
        "í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ ìŠ¤í‚¤ë§ˆ êµ¬ì¡°(Incident, Entity ë“±)ë¥¼ ì•Œë ¤ì¤˜.",
        "CVE-2025-14847 ì·¨ì•½ì ê³¼ 'í•œêµ­ìˆ˜ë ¥ì›ìë ¥ ì›ì „ì œì–´ë§' ì‚¬ì´ì— ì—°ê²°ì (ì—°ê´€ì„±)ì´ ìˆëŠ”ì§€ ì°¾ì•„ì¤˜.",
        "ë¸”ë¡ì²´ì¸ ë˜ëŠ” ê°€ìƒí™”íì™€ ê´€ë ¨ëœ ì‚¬ê±´ì„ ì–´ë–¤ ê³µê²©ìê°€ ì£¼ë¡œ í•˜ê³  ìˆëŠ”ì§€ ì°¾ì•„ì¤˜.",
        "IP '101.35.56.7'ì´ í¬í•¨ëœ ì¹¨í•´ ì‚¬ê³  ì •ë³´ë¥¼ ì°¾ì•„ì¤˜.",
        "ìµœê·¼ 6ê°œì›” ë‚´ì— 'Turla' ìœ„í˜‘ ê·¸ë£¹ì´ ê´€ë ¨ëœ ì‚¬ê±´ë“¤ì„ ì•Œë ¤ì¤˜.",
        "Malware 'TrickBot'ì´ ì—°ê´€ëœ ì‚¬ê±´ë“¤ì˜ IoCë“¤ì„ ì°¾ì•„ì¤˜"
    ]

    for q in sample_questions:
        if st.button(q, use_container_width=True):
            st.session_state.trigger_query = q
            st.session_state.followup_suggestions = [] # ìƒˆ ì§ˆë¬¸ì´ë¯€ë¡œ ê¸°ì¡´ ì¶”ì²œ ì´ˆê¸°í™”
            st.rerun()
            
    st.markdown("---")
    st.info("ğŸ’¡ **Tip:** ë¦¬í¬íŠ¸ë¥¼ ë¨¼ì € `Intelligence Processing` ë©”ë‰´ì—ì„œ ë“±ë¡í•´ì•¼ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# ==============================================================================
# 4. ë©”ì¸ ë¡œì§ í•¨ìˆ˜
# ==============================================================================
# ==============================================================================
# 4. ë©”ì¸ ë¡œì§ í•¨ìˆ˜
# ==============================================================================
def process_query(user_input):
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ UI í‘œì‹œ ë° ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # 2. ì—ì´ì „íŠ¸ ì‹¤í–‰
    final_response = ""
    current_steps = [] # ì´ë²ˆ í„´ì˜ ë„êµ¬ í˜¸ì¶œ ê¸°ë¡ ì €ì¥ìš©
    
    # UIì— ê·¸ë¦¬ê¸°
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        status_placeholder = st.status("ğŸ§  Agent is reasoning...", expanded=True)
        
        try:
            graph = agent.build_agent_graph()
            
            current_human_msg = HumanMessage(content=user_input)
            input_messages = st.session_state.langchain_history + [current_human_msg]
            
            step_count = 0
            
            with status_placeholder:
                for event in graph.stream({"messages": input_messages}, stream_mode="values"):
                    current_state_messages = event["messages"]
                    if not current_state_messages: continue
                    
                    last_msg = current_state_messages[-1]
                    
                    # Tool í˜¸ì¶œ ê²°ì • ì‹œ
                    if isinstance(last_msg, AIMessage) and last_msg.tool_calls:
                        for tc in last_msg.tool_calls:
                            step_count += 1
                            msg_text = f"**Step {step_count}:** ğŸ¤” Decided to use tool `{tc['name']}`"
                            st.write(msg_text)
                            current_steps.append({"type": "call", "count": step_count, "name": tc['name'], "args": tc['args']})
                            with st.expander(f"Arguments for {tc['name']}", expanded=False):
                                st.code(json.dumps(tc['args'], indent=2, ensure_ascii=False), language="json")

                    # Tool ì‹¤í–‰ ê²°ê³¼
                    elif isinstance(last_msg, ToolMessage):
                        msg_text = f"**Step {step_count}:** ğŸ” Tool Output (`{last_msg.name}`)"
                        st.write(msg_text)
                        current_steps.append({"type": "result", "count": step_count, "name": last_msg.name, "content": last_msg.content})
                        with st.expander("Show Result", expanded=False):
                            raw = last_msg.content or ""
                            try:
                                content_json = json.loads(raw)
                                st.json(content_json)
                            except Exception:
                                st.code(raw, language="text")

                    # ìµœì¢… ë‹µë³€
                    elif isinstance(last_msg, AIMessage) and last_msg.content:
                        if not last_msg.tool_calls:
                            final_response = last_msg.content
            
            status_placeholder.update(label="âœ… Analysis Complete", state="complete", expanded=False)
            
            if final_response:
                response_placeholder.markdown(final_response)
                
                # ëŒ€í™” ê¸°ë¡ ì €ì¥ (steps í¬í•¨)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": final_response,
                    "steps": current_steps
                })
                st.session_state.langchain_history.append(current_human_msg)
                st.session_state.langchain_history.append(AIMessage(content=final_response))
                
                # í›„ì† ì§ˆë¬¸ ìƒì„±
                suggestions = generate_followup_questions(user_input, final_response)
                st.session_state.followup_suggestions = suggestions
                st.rerun()
                
            else:
                response_placeholder.error("ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            status_placeholder.update(label="âŒ Error Occurred", state="error")
            st.error(f"Error Details: {e}")

# ==============================================================================
# 5. í™”ë©´ ë Œë”ë§ ë£¨í”„
# ==============================================================================

# A. ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥ 
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        # [ì¶”ê°€] ì—ì´ì „íŠ¸ì˜ ì‚¬ê³  ê³¼ì •(Steps)ì´ ìˆë‹¤ë©´ í™•ì¥ ë²„íŠ¼ìœ¼ë¡œ í‘œì‹œ
        if msg["role"] == "assistant" and msg.get("steps"):
            with st.expander("ğŸ” ë¶„ì„ ì‚¬ê³  ê³¼ì • (Tool Execution Logs)", expanded=False):
                for s in msg["steps"]:
                    if s["type"] == "call":
                        st.write(f"**Step {s['count']}:** ğŸ› ï¸ `{s['name']}` ë„êµ¬ ì‚¬ìš© ê²°ì •")
                        st.caption("ì…ë ¥ íŒŒë¼ë¯¸í„°:")
                        st.code(json.dumps(s['args'], indent=2, ensure_ascii=False), language="json")
                    else:
                        st.write(f"**Step {s['count']}:** ğŸ“¥ `{s['name']}` ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì‹ ")
                        try:
                            st.json(json.loads(s['content']))
                        except:
                            st.code(s['content'], language="text")
                st.divider()
        
        st.markdown(msg["content"])

# B. í›„ì† ì§ˆë¬¸ ì„ íƒì§€ ì¶œë ¥ (ë§ˆì§€ë§‰ì´ AI ë‹µë³€ì¼ ë•Œë§Œ)
if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
    if st.session_state.followup_suggestions:
        st.write("ğŸ‘‰ **Suggested Questions:**")
        cols = st.columns(len(st.session_state.followup_suggestions))
        for idx, suggestion in enumerate(st.session_state.followup_suggestions):
            if cols[idx].button(suggestion, key=f"suggest_{len(st.session_state.messages)}_{idx}"):
                st.session_state.trigger_query = suggestion
                st.session_state.followup_suggestions = [] # ì„ íƒí–ˆìœ¼ë‹ˆ ì´ˆê¸°í™”
                st.rerun()

# C. íŠ¸ë¦¬ê±° í™•ì¸ (ì‚¬ì´ë“œë°” ë˜ëŠ” ì¶”ì²œ ì§ˆë¬¸ í´ë¦­ ì‹œ)
if st.session_state.trigger_query:
    query = st.session_state.trigger_query
    st.session_state.trigger_query = None # ì†Œë¹„
    process_query(query)

# D. ì±„íŒ… ì…ë ¥ì°½ (í•­ìƒ ìµœí•˜ë‹¨ì— ìœ ì§€ë¨)
if prompt := st.chat_input("ë³´ì•ˆ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì´ IPëŠ” ì–´ë–¤ ì‚¬ê±´ê³¼ ì—°ê´€ë¼?)..."):
    st.session_state.followup_suggestions = [] # ìƒˆ ì§ˆë¬¸ ì…ë ¥ ì‹œ ì¶”ì²œ ì´ˆê¸°í™”
    process_query(prompt)