import streamlit as st
import sys
import os
import requests
import socket
from time import sleep

# [ê²½ë¡œ ì„¤ì •]
# apps/ui/Home.py ìœ„ì¹˜ì—ì„œ í”„ë¡œì íŠ¸ ë£¨íŠ¸(coin)ê¹Œì§€ì˜ ê²½ë¡œ
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from src.core.config import settings
from src.core.graph_client import graph_client

# ==============================================================================
# 1. í˜ì´ì§€ ì„¤ì •
# ==============================================================================
st.set_page_config(
    page_title="COIN",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# ==============================================================================
# 2. í—¬í¼ í•¨ìˆ˜: ìƒíƒœ ì ê²€
# ==============================================================================

def check_neo4j_status():
    """Neo4j ë„ì»¤ ì»¨í…Œì´ë„ˆ ë° DB ì ‘ì† ìƒíƒœ í™•ì¸"""
    try:
        # graph_clientë¥¼ ì´ìš©í•´ ê°€ë²¼ìš´ ì¿¼ë¦¬ ì‹¤í–‰
        # ì´ê²ƒì´ ì„±ê³µí•˜ë©´ ë„ì»¤ ì»¨í…Œì´ë„ˆê°€ ì¼œì ¸ ìˆê³ , í¬íŠ¸ê°€ ì—´ë ¤ ìˆê³ , ì¸ì¦ë„ ì„±ê³µí•œ ê²ƒì„
        result = graph_client.query("RETURN 1")
        if result and result[0]['1'] == 1:
            return True, "Running"
    except Exception as e:
        return False, str(e)
    return False, "Connection Failed"

def check_llm_status():
    """LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    if settings.LLM_PROVIDER == "ollama":
        try:
            # Ollama Health check or Tags check
            res = requests.get(f"{settings.OLLAMA_BASE_URL}/api/tags", timeout=2)
            if res.status_code == 200:
                return True, "Running (Local)"
        except:
            return False, "Ollama Stopped"
    else:
        # OpenAIëŠ” API Key ì¡´ì¬ ì—¬ë¶€ë¡œ íŒë‹¨ (ì‹¤ì œ í˜¸ì¶œì€ ë¹„ìš© ë¬¸ì œë¡œ ìƒëµ)
        if settings.OPENAI_API_KEY:
            return True, "Active (Cloud)"
        else:
            return False, "API Key Missing"
    return False, "Unknown"

# ==============================================================================
# 3. UI êµ¬ì„±
# ==============================================================================

# í—¤ë”
hl = "color: #FF4B4B; font-weight: bold;"

st.markdown(f"""
    <h1 style='font-family: sans-serif;'>
        ğŸ›¡ï¸ COIN : 
        <span style='{hl}'>C</span>yber 
        <span style='{hl}'>O</span>ntology 
        <span style='{hl}'>IN</span>telligence
    </h1>
""", unsafe_allow_html=True)
st.markdown("##### *Knowledge Graph driven Threat Analysis Platform*")
st.markdown("---")

# ì‹œìŠ¤í…œ ìƒíƒœ ëŒ€ì‹œë³´ë“œ (Metrics)
st.subheader("ğŸ“Š System Dashboard")
col1, col2, col3, col4 = st.columns(4)

# 1. LLM Provider Info
with col1:
    st.info("**AI Model Config**")
    current_model = settings.OPENAI_MODEL if settings.LLM_PROVIDER == 'openai' else settings.OLLAMA_MODEL
    st.write(f"- **Provider:** `{settings.LLM_PROVIDER.upper()}`")
    st.write(f"- **Model:** `{current_model}`")

# 2. Neo4j (Docker) Status
with col2:
    is_up, status_msg = check_neo4j_status()
    st.metric(
        label="Neo4j Container (Graph DB)", 
        value="Online" if is_up else "Offline", 
        delta="Connected" if is_up else "Error",
        delta_color="normal" if is_up else "inverse"
    )
    if not is_up:
        st.caption(f"âš ï¸ {status_msg}")

# 3. LLM Service Status
with col3:
    llm_up, llm_msg = check_llm_status()
    st.metric(
        label="LLM Service Status",
        value="Ready" if llm_up else "Not Ready",
        delta=llm_msg,
        delta_color="normal" if llm_up else "inverse"
    )

# 4. Data Graph Info
with col4:
    # DBì— ìˆëŠ” ë…¸ë“œ ê°œìˆ˜ ì‚´ì§ ë³´ì—¬ì£¼ê¸°
    try:
        count_res = graph_client.query("MATCH (n) RETURN count(n) as cnt")
        total_nodes = count_res[0]['cnt'] if count_res else 0
        st.metric(label="Total Knowledge Nodes", value=f"{total_nodes:,}", delta="Entities")
    except:
        st.metric(label="Total Knowledge Nodes", value="Unknown", delta="Sync Error")

st.markdown("---")

# ë„¤ë¹„ê²Œì´ì…˜ ê°€ì´ë“œ
st.subheader("ğŸ§­ Analysis Modules")
st.markdown("""
ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”. ì´ ì‹œìŠ¤í…œì€ **MITRE ATT&CK, CISA KEV, URLHaus** ë° **ìƒì„±ëœ ì‹œë‚˜ë¦¬ì˜¤** ë°ì´í„°ë¥¼ í†µí•© ë¶„ì„í•©ë‹ˆë‹¤.
""")

# [ë³€ê²½] 4ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ í™•ì¥
mode_col1, mode_col2, mode_col3, mode_col4 = st.columns(4)

with mode_col1:
    st.markdown("""
    ### 1. Deep Analysis
    **ì‹¬ì¸µ ë¶„ì„ ë° í”„ë¡œíŒŒì¼ë§**
    * Incident, Threat Group, Malware, CVEì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    * LLMê³¼ ê·¸ë˜í”„ ë°ì´í„°ë¥¼ ê²°í•©í•œ ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """)

with mode_col2:
    st.markdown("""
    ### 2. Correlation
    **ìœ„í˜‘ ì—°ê´€ì„± ë¶„ì„**
    * IP, Hash, URL ë“± íŒŒí¸í™”ëœ IoCë¥¼ ì…ë ¥í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
    * ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ìˆ¨ê²¨ì§„ ê³µê²© ìº í˜ì¸ê³¼ ë°°í›„ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
    """)

with mode_col3:
    st.markdown("""
    ### 3. Smart Agent
    **AI ììœ¨ ì—ì´ì „íŠ¸**
    * ìì—°ì–´ë¡œ ë³´ì•ˆ ê´€ë ¨ ì§ˆë¬¸ì„ ë˜ì ¸ë³´ì„¸ìš”.
    * AIê°€ ìŠ¤ìŠ¤ë¡œ Cypher ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì—¬ DBë¥¼ íƒìƒ‰í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤.
    """)

with mode_col4:
    st.markdown("""
    ### 4. Scenario Explorer
    **ì‹œë‚˜ë¦¬ì˜¤ íƒìƒ‰ê¸° (New!)**
    * AIê°€ ìƒì„±í•œ ê°€ìƒ ì¹¨í•´ ì‚¬ê³ (Incident)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    * ê³µê²© ë‹¨ê³„(Kill Chain)ë³„ ìƒì„¸ íë¦„ê³¼ ì•„í‹°íŒ©íŠ¸ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """)

# í‘¸í„°
st.markdown("---")
st.caption("Â© 2026 Cyber Ontology Intelligence Project. Powered by Neo4j & LangGraph.")