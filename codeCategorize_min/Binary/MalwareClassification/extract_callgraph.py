#!/usr/bin/env python3
"""
Call Graph Extraction for Malware Family Classification
Extracts function call graphs (nodes and edges) from binaries using pyGhidra
WITH PARALLEL DECOMPILATION SUPPORT
"""

import os
import sys
import json
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
import multiprocessing
import datetime

# =============================================================================
# Environment Setup
# =============================================================================

import pyghidra

# =============================================================================
# Global Variables
# =============================================================================
GHIDRA_PROJECTS_DIR = Path("projects")
GHIDRA_PROJECTS_DIR.mkdir(exist_ok=True)

# Thread-safe print lock
_print_lock = Lock()

# Initialize PyGhidra (only once)
_pyghidra_initialized = False

def initialize_pyghidra():
    """Initialize PyGhidra if not already initialized"""
    global _pyghidra_initialized
    if not _pyghidra_initialized:
        try:
            pyghidra.start()
            _pyghidra_initialized = True
            print("✔ PyGhidra initialized successfully")
        except Exception as e:
            if "already" in str(e).lower() or "started" in str(e).lower():
                _pyghidra_initialized = True
                print("✔ PyGhidra already initialized")
            else:
                raise


# =============================================================================
# Parallel Decompilation Helper
# =============================================================================

class DecompilerWorker:
    """
    Thread-local decompiler wrapper.
    Each thread gets its own DecompInterface instance.
    """
    def __init__(self, program, timeout=120):
        from ghidra.app.decompiler import DecompInterface
        from ghidra.util.task import ConsoleTaskMonitor
        
        self.decompiler = DecompInterface()
        self.decompiler.openProgram(program)
        self.monitor = ConsoleTaskMonitor()
        self.timeout = timeout
    
    def decompile(self, func):
        """Decompile a single function and return the result"""
        try:
            results = self.decompiler.decompileFunction(func, self.timeout, self.monitor)
            if results and results.decompileCompleted():
                decomp_func = results.getDecompiledFunction()
                high_func = results.getHighFunction()
                if decomp_func:
                    return {
                        'success': True,
                        'code': decomp_func.getC(),
                        'high_func': high_func,
                        'func': func
                    }
            return {'success': False, 'func': func, 'code': '', 'high_func': None}
        except Exception as e:
            return {'success': False, 'func': func, 'code': '', 'high_func': None, 'error': str(e)}
    
    def dispose(self):
        """Clean up resources"""
        try:
            self.decompiler.dispose()
        except:
            pass


def parallel_decompile_functions(program, functions, thread_count=None, timeout=120):
    """
    Decompile functions in parallel using multiple DecompInterface instances.
    
    Args:
        program: Ghidra program object
        functions: List of Function objects to decompile
        thread_count: Number of threads (default: CPU count)
        timeout: Decompilation timeout per function
    
    Returns:
        dict: {function_entry_point: decompile_result}
    """
    if thread_count is None:
        thread_count = min(multiprocessing.cpu_count(), 8)  # Cap at 8 threads
    
    results = {}
    total = len(functions)
    completed = [0]  # Use list for mutable counter in closure
    
    def decompile_batch(func_batch, worker_id):
        """Worker function that processes a batch of functions"""
        from ghidra.app.decompiler import DecompInterface
        from ghidra.util.task import ConsoleTaskMonitor
        
        # Create thread-local decompiler
        decompiler = DecompInterface()
        decompiler.openProgram(program)
        monitor = ConsoleTaskMonitor()
        
        batch_results = {}
        try:
            for func in func_batch:
                try:
                    res = decompiler.decompileFunction(func, timeout, monitor)
                    addr_str = str(func.getEntryPoint())
                    
                    if res and res.decompileCompleted():
                        decomp_func = res.getDecompiledFunction()
                        high_func = res.getHighFunction()
                        if decomp_func:
                            batch_results[addr_str] = {
                                'success': True,
                                'code': decomp_func.getC(),
                                'high_func': high_func,
                                'func': func
                            }
                        else:
                            batch_results[addr_str] = {
                                'success': False, 'func': func, 
                                'code': '', 'high_func': None
                            }
                    else:
                        batch_results[addr_str] = {
                            'success': False, 'func': func, 
                            'code': '', 'high_func': None
                        }
                    
                    # Update progress
                    with _print_lock:
                        completed[0] += 1
                        if completed[0] % 100 == 0:
                            print(f"    Decompiled {completed[0]}/{total} ({100*completed[0]//total}%)")
                            
                except Exception as e:
                    addr_str = str(func.getEntryPoint())
                    batch_results[addr_str] = {
                        'success': False, 'func': func, 
                        'code': '', 'high_func': None, 'error': str(e)
                    }
        finally:
            # IMPORTANT: Always dispose decompiler to prevent resource leak
            decompiler.dispose()
        
        return batch_results
    
    # Distribute functions across workers
    func_list = list(functions)
    batch_size = max(1, len(func_list) // thread_count)
    batches = []
    
    for i in range(0, len(func_list), batch_size):
        batches.append(func_list[i:i + batch_size])
    
    print(f"  Decompiling {total} functions using {len(batches)} threads...")
    
    # Use ThreadPoolExecutor for parallel execution
    with ThreadPoolExecutor(max_workers=thread_count) as executor:
        futures = {
            executor.submit(decompile_batch, batch, idx): idx 
            for idx, batch in enumerate(batches)
        }
        
        for future in as_completed(futures):
            try:
                batch_results = future.result()
                results.update(batch_results)
            except Exception as e:
                print(f"    Warning: Batch failed with error: {e}")
    
    return results


# =============================================================================
# Feature Extraction (Updated with Parallel Decompilation)
# =============================================================================

def extract_callgraph_from_binary(binary_path, family_name, output_dir=None, 
                                   timeout=120, thread_count=None):
    """
    Extract call graph features from a binary using pyGhidra with parallel decompilation.

    Args:
        binary_path: Path to the binary file
        family_name: Malware family name (folder name)
        output_dir: Directory to save JSON output (default: ./output)
        timeout: Decompilation timeout in seconds
        thread_count: Number of parallel decompilation threads

    Returns:
        dict: Extracted features in JSON format, or None if failed
    """
    initialize_pyghidra()

    binary_path = Path(binary_path)
    if output_dir is None:
        output_dir = Path("./output")
    else:
        output_dir = Path(output_dir)

    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / f"{binary_path.stem}.json"

    print(f"\nProcessing: {binary_path.name}")
    print(f"  Family: {family_name}")

    # Create unique project name
    import time
    project_name = f"temp_{os.getpid()}_{binary_path.stem}_{int(time.time() * 1000)}"

    try:
        nodes = []
        edges = []
        address_to_id = {}
        next_node_id = 0
        print(str(datetime.datetime.now()) + " - Opening Program")
        # Open binary with PyGhidra
        with pyghidra.open_program(
            str(binary_path),
            project_location=str(GHIDRA_PROJECTS_DIR),
            project_name=project_name,
            analyze=True
        ) as flat_api:

            from ghidra.util.task import ConsoleTaskMonitor

            program = flat_api.getCurrentProgram()
            fm = program.getFunctionManager()
            monitor = ConsoleTaskMonitor()

            # Collect non-external functions
            functions_to_decompile = []
            func_info_map = {}  # Store basic info before decompilation
            print(str(datetime.datetime.now()) + " - Getting Functions")
            for func in fm.getFunctions(True):
                if func.isExternal():
                    continue
                
                addr_str = str(func.getEntryPoint())
                node_id = next_node_id
                address_to_id[addr_str] = node_id
                next_node_id += 1
                
                # Extract basic info (doesn't require decompilation)
                num_params = 0
                try:
                    params = func.getParameters()
                    if params is not None:
                        num_params = len(params)
                    if num_params == 0:
                        num_params = func.getParameterCount()
                except:
                    pass
                
                return_type = str(func.getReturnType())
                
                num_variables = 0
                try:
                    local_vars = func.getLocalVariables()
                    if local_vars is not None:
                        num_variables = len(list(local_vars))
                except:
                    pass
                
                instruction_size = 0
                try:
                    func_body = func.getBody()
                    if func_body:
                        instruction_size = func_body.getNumAddresses()
                except:
                    pass
                
                func_info_map[addr_str] = {
                    'node_id': node_id,
                    'num_params': num_params,
                    'return_type': return_type,
                    'num_variables': num_variables,
                    'instruction_size': instruction_size,
                    'func': func
                }
                
                functions_to_decompile.append(func)
                
                # Extract edges (call graph)
                try:
                    called_funcs = func.getCalledFunctions(monitor)
                    if called_funcs:
                        for called_func in called_funcs:
                            if called_func.isExternal():
                                continue
                            called_addr = str(called_func.getEntryPoint())
                            edges.append({
                                'from_addr': addr_str,
                                'to_addr': called_addr
                            })
                except:
                    pass

            print(f"  Found {len(functions_to_decompile)} functions to decompile")
            print(str(datetime.datetime.now()) + " - Decompile Start")
            # ===================================================================
            # PARALLEL DECOMPILATION
            # ===================================================================
            decompile_results = parallel_decompile_functions(
                program, 
                functions_to_decompile,
                thread_count=thread_count,
                timeout=timeout
            )
            print(str(datetime.datetime.now()) + " - Decompile End")
            # ===================================================================
            # Build nodes from decompilation results
            # ===================================================================
            decompiled_count = 0
            
            for addr_str, info in func_info_map.items():
                decompiled_code = ""
                num_params = info['num_params']
                num_variables = info['num_variables']
                
                # Get decompilation result
                if addr_str in decompile_results:
                    result = decompile_results[addr_str]
                    if result['success'] and result['code']:
                        decompiled_code = result['code']
                        decompiled_count += 1
                        
                        # Update params/vars from HighFunction if available
                        high_func = result.get('high_func')
                        if high_func:
                            try:
                                local_symbol_map = high_func.getLocalSymbolMap()
                                if local_symbol_map:
                                    param_count = local_symbol_map.getNumParams()
                                    if param_count > 0:
                                        num_params = param_count
                                    all_symbols = local_symbol_map.getSymbols()
                                    if all_symbols:
                                        num_variables = len(list(all_symbols)) - param_count
                            except:
                                pass
                
                node = {
                    "NodeID": info['node_id'],
                    "InputParameterSize": num_params,
                    "InstructionSize": info['instruction_size'],
                    "ReturnDataType": info['return_type'],
                    "VariableSize": num_variables,
                    "DecompileContent": decompiled_code,
                    "DecompileEmbedding": []
                }
                nodes.append(node)

        # ===================================================================
        # Check results
        # ===================================================================
        if decompiled_count == 0:
            print(f"  ⚠ No functions were decompiled. Skipping JSON generation.")
            return None

        print(f"  ✔ Extracted {len(nodes)} nodes ({decompiled_count} decompiled)")

        # Resolve edge IDs
        resolved_edges = []
        for edge in edges:
            from_addr = edge['from_addr']
            to_addr = edge['to_addr']
            if from_addr in address_to_id and to_addr in address_to_id:
                resolved_edges.append({
                    "from": address_to_id[from_addr],
                    "to": address_to_id[to_addr]
                })

        print(f"  ✔ Extracted {len(resolved_edges)} edges")

        # Create output JSON
        output_data = {
            "Family": family_name,
            "Nodes": nodes,
            "Edges": resolved_edges
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        print(f"  ✔ Saved to: {output_file}")

        return output_data

    except Exception as e:
        print(f"  ✗ Error: {e}")
        import traceback
        traceback.print_exc()
        return None

    finally:
        # Clean up temporary Ghidra project
        temp_project = GHIDRA_PROJECTS_DIR / project_name
        if temp_project.exists():
            try:
                shutil.rmtree(temp_project, ignore_errors=True)
            except:
                pass


# =============================================================================
# Alternative: Using Ghidra's Built-in ParallelDecompiler
# =============================================================================

def extract_callgraph_using_parallel_decompiler(binary_path, family_name, 
                                                  output_dir=None, timeout=120):
    """
    Alternative implementation using Ghidra's native ParallelDecompiler.
    This is more efficient as it uses Ghidra's internal thread pool.
    """
    initialize_pyghidra()
    
    binary_path = Path(binary_path)
    if output_dir is None:
        output_dir = Path("./output")
    else:
        output_dir = Path(output_dir)

    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / f"{binary_path.stem}.json"

    print(f"\nProcessing (ParallelDecompiler): {binary_path.name}")
    print(f"  Family: {family_name}")

    import time
    project_name = f"temp_{os.getpid()}_{binary_path.stem}_{int(time.time() * 1000)}"

    try:
        nodes = []
        edges = []
        address_to_id = {}
        decompile_results = {}

        with pyghidra.open_program(
            str(binary_path),
            project_location=str(GHIDRA_PROJECTS_DIR),
            project_name=project_name,
            analyze=True
        ) as flat_api:

            from ghidra.app.decompiler import DecompileOptions
            from ghidra.app.decompiler.parallel import ParallelDecompiler, DecompilerCallback
            from ghidra.util.task import ConsoleTaskMonitor
            from java.util.function import Consumer

            program = flat_api.getCurrentProgram()
            fm = program.getFunctionManager()
            monitor = ConsoleTaskMonitor()

            # Collect functions and build address map
            functions_list = []
            func_info_map = {}
            next_node_id = 0

            for func in fm.getFunctions(True):
                if func.isExternal():
                    continue
                
                addr_str = str(func.getEntryPoint())
                address_to_id[addr_str] = next_node_id
                
                # Basic info
                num_params = 0
                try:
                    params = func.getParameters()
                    num_params = len(params) if params else func.getParameterCount()
                except:
                    pass
                
                num_variables = 0
                try:
                    local_vars = func.getLocalVariables()
                    num_variables = len(list(local_vars)) if local_vars else 0
                except:
                    pass
                
                instruction_size = 0
                try:
                    func_body = func.getBody()
                    instruction_size = func_body.getNumAddresses() if func_body else 0
                except:
                    pass
                
                func_info_map[addr_str] = {
                    'node_id': next_node_id,
                    'num_params': num_params,
                    'return_type': str(func.getReturnType()),
                    'num_variables': num_variables,
                    'instruction_size': instruction_size
                }
                
                next_node_id += 1
                functions_list.append(func)
                
                # Edges
                try:
                    for called_func in func.getCalledFunctions(monitor):
                        if not called_func.isExternal():
                            edges.append({
                                'from_addr': addr_str,
                                'to_addr': str(called_func.getEntryPoint())
                            })
                except:
                    pass

            print(f"  Found {len(functions_list)} functions")

            # ===================================================================
            # Use Ghidra's ParallelDecompiler with custom callback
            # ===================================================================
            
            # Create a custom callback class
            class MyDecompilerCallback(DecompilerCallback):
                def __init__(self, prog):
                    super().__init__(prog, DecompileOptions())
                    self.results = {}
                    self.count = [0]
                
                def process(self, decompile_results, task_monitor):
                    func = decompile_results.getFunction()
                    addr_str = str(func.getEntryPoint())
                    
                    code = ""
                    high_func = None
                    
                    if decompile_results.decompileCompleted():
                        decomp_func = decompile_results.getDecompiledFunction()
                        if decomp_func:
                            code = decomp_func.getC()
                        high_func = decompile_results.getHighFunction()
                    
                    self.results[addr_str] = {
                        'code': code,
                        'high_func': high_func
                    }
                    
                    self.count[0] += 1
                    if self.count[0] % 100 == 0:
                        print(f"    Decompiled {self.count[0]} functions...")
                    
                    return code  # Return value for ParallelDecompiler
            
            callback = MyDecompilerCallback(program)
            
            try:
                print(f"  Starting parallel decompilation...")
                
                # Use ParallelDecompiler
                ParallelDecompiler.decompileFunctions(
                    callback,
                    program,
                    program.getMemory(),
                    monitor
                )
                
                decompile_results = callback.results
                
            finally:
                callback.dispose()

            # Build nodes
            decompiled_count = 0
            for addr_str, info in func_info_map.items():
                code = ""
                num_params = info['num_params']
                num_variables = info['num_variables']
                
                if addr_str in decompile_results:
                    res = decompile_results[addr_str]
                    code = res.get('code', '')
                    if code:
                        decompiled_count += 1
                    
                    high_func = res.get('high_func')
                    if high_func:
                        try:
                            lsm = high_func.getLocalSymbolMap()
                            if lsm:
                                pc = lsm.getNumParams()
                                if pc > 0:
                                    num_params = pc
                                syms = lsm.getSymbols()
                                if syms:
                                    num_variables = len(list(syms)) - pc
                        except:
                            pass
                
                nodes.append({
                    "NodeID": info['node_id'],
                    "InputParameterSize": num_params,
                    "InstructionSize": info['instruction_size'],
                    "ReturnDataType": info['return_type'],
                    "VariableSize": num_variables,
                    "DecompileContent": code,
                    "DecompileEmbedding": []
                })

        if decompiled_count == 0:
            print(f"  ⚠ No functions were decompiled.")
            return None

        print(f"  ✔ Extracted {len(nodes)} nodes ({decompiled_count} decompiled)")

        # Resolve edges
        resolved_edges = []
        for edge in edges:
            if edge['from_addr'] in address_to_id and edge['to_addr'] in address_to_id:
                resolved_edges.append({
                    "from": address_to_id[edge['from_addr']],
                    "to": address_to_id[edge['to_addr']]
                })

        print(f"  ✔ Extracted {len(resolved_edges)} edges")

        output_data = {
            "Family": family_name,
            "Nodes": nodes,
            "Edges": resolved_edges
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        print(f"  ✔ Saved to: {output_file}")
        return output_data

    except Exception as e:
        print(f"  ✗ Error: {e}")
        import traceback
        traceback.print_exc()
        return None

    finally:
        temp_project = GHIDRA_PROJECTS_DIR / project_name
        if temp_project.exists():
            try:
                shutil.rmtree(temp_project, ignore_errors=True)
            except:
                pass


# =============================================================================
# Main
# =============================================================================

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python extract_callgraph_parallel.py <binary_path> <family_name> [output_dir] [thread_count]")
        print("Example: python extract_callgraph_parallel.py malware.exe FamilyName ./output 8")
        sys.exit(1)

    binary_path = sys.argv[1]
    family_name = sys.argv[2]
    output_dir = sys.argv[3] if len(sys.argv) > 3 else "./output"
    thread_count = int(sys.argv[4]) if len(sys.argv) > 4 else None

    # Use Python ThreadPoolExecutor version (more compatible)
    result = extract_callgraph_from_binary(
        binary_path, 
        family_name, 
        output_dir,
        thread_count=thread_count
    )
    
    # Alternative: Use Ghidra's native ParallelDecompiler
    # result = extract_callgraph_using_parallel_decompiler(
    #     binary_path, 
    #     family_name, 
    #     output_dir
    # )

    if result:
        print("\n✔ Call graph extraction completed successfully!")
    else:
        print("\n✗ Call graph extraction failed!")
        sys.exit(1)
